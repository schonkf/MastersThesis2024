{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee1b6037-ce61-42df-a9e1-858c8fc37c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from hyperopt import hp\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import mode\n",
    "import shap\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bba98322-7983-4c24-ae0a-37f3c9478627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tabular= pd.read_csv('/Users/finnschonknecht/Desktop/XGB_train_folder/tabular.csv')\n",
    "targets = pd.read_csv('/Users/finnschonknecht/Desktop/XGB_train_folder/binary_personalised_targets.csv')\n",
    "personality_df = pd.read_csv('/Users/finnschonknecht/Desktop/XGB_train_folder/personality_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7cb42ac-b902-4773-882f-15724543e36a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_code_counts = tabular.groupby('Pcode').size().reset_index(name='counts')\n",
    "p_code_counts = pd.DataFrame(p_code_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a5e6e44-371d-4faf-9d81-0c1569f07a31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_code_counts.counts.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a758a3d2-caaf-4d27-bd87-47035c010ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseTime</th>\n",
       "      <th>Pcode</th>\n",
       "      <th>Stress_binary</th>\n",
       "      <th>Valence_binary</th>\n",
       "      <th>Arousal_binary</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>...</th>\n",
       "      <th>6hr_WEATHER_number_of_events</th>\n",
       "      <th>previous_nights_sleep_proxy</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>day_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-08 09:09:48+09:00</td>\n",
       "      <td>P19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761660</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-08 10:13:10+09:00</td>\n",
       "      <td>P19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761660</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-08 10:41:14+09:00</td>\n",
       "      <td>P19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761660</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-08 11:24:43+09:00</td>\n",
       "      <td>P19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761660</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-08 12:10:15+09:00</td>\n",
       "      <td>P19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761660</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5433</th>\n",
       "      <td>2019-05-05 19:37:56+09:00</td>\n",
       "      <td>P62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.066579</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>2019-05-05 20:45:53+09:00</td>\n",
       "      <td>P62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.066579</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>2019-05-05 21:43:23+09:00</td>\n",
       "      <td>P62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.066579</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5436</th>\n",
       "      <td>2019-05-05 23:10:51+09:00</td>\n",
       "      <td>P62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.066579</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5437</th>\n",
       "      <td>2019-05-06 18:16:26+09:00</td>\n",
       "      <td>P62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.584967</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5438 rows Ã— 1211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ResponseTime Pcode  Stress_binary  Valence_binary  \\\n",
       "0     2019-05-08 09:09:48+09:00   P19            0.0             1.0   \n",
       "1     2019-05-08 10:13:10+09:00   P19            1.0             0.0   \n",
       "2     2019-05-08 10:41:14+09:00   P19            1.0             1.0   \n",
       "3     2019-05-08 11:24:43+09:00   P19            1.0             1.0   \n",
       "4     2019-05-08 12:10:15+09:00   P19            0.0             1.0   \n",
       "...                         ...   ...            ...             ...   \n",
       "5433  2019-05-05 19:37:56+09:00   P62            0.0             1.0   \n",
       "5434  2019-05-05 20:45:53+09:00   P62            1.0             1.0   \n",
       "5435  2019-05-05 21:43:23+09:00   P62            1.0             0.0   \n",
       "5436  2019-05-05 23:10:51+09:00   P62            0.0             1.0   \n",
       "5437  2019-05-06 18:16:26+09:00   P62            1.0             1.0   \n",
       "\n",
       "      Arousal_binary  Age Gender  Openness  Conscientiousness  Neuroticism  \\\n",
       "0                1.0   18      M        12                 13            3   \n",
       "1                1.0   18      M        12                 13            3   \n",
       "2                1.0   18      M        12                 13            3   \n",
       "3                0.0   18      M        12                 13            3   \n",
       "4                1.0   18      M        12                 13            3   \n",
       "...              ...  ...    ...       ...                ...          ...   \n",
       "5433             0.0   20      M        15                 15            9   \n",
       "5434             1.0   20      M        15                 15            9   \n",
       "5435             0.0   20      M        15                 15            9   \n",
       "5436             0.0   20      M        15                 15            9   \n",
       "5437             1.0   20      M        15                 15            9   \n",
       "\n",
       "      ...  6hr_WEATHER_number_of_events  previous_nights_sleep_proxy  \\\n",
       "0     ...                           NaN                     0.761660   \n",
       "1     ...                           NaN                     0.761660   \n",
       "2     ...                           NaN                     0.761660   \n",
       "3     ...                           NaN                     0.761660   \n",
       "4     ...                           NaN                     0.761660   \n",
       "...   ...                           ...                          ...   \n",
       "5433  ...                           NaN                    11.066579   \n",
       "5434  ...                           NaN                    11.066579   \n",
       "5435  ...                           NaN                    11.066579   \n",
       "5436  ...                           NaN                    11.066579   \n",
       "5437  ...                           NaN                     9.584967   \n",
       "\n",
       "      hour_of_day  day_0  day_1  day_2  day_3  day_4  day_5  day_6  \n",
       "0               9      0      0      1      0      0      0      0  \n",
       "1              10      0      0      1      0      0      0      0  \n",
       "2              10      0      0      1      0      0      0      0  \n",
       "3              11      0      0      1      0      0      0      0  \n",
       "4              12      0      0      1      0      0      0      0  \n",
       "...           ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "5433           19      0      0      0      0      0      0      1  \n",
       "5434           20      0      0      0      0      0      0      1  \n",
       "5435           21      0      0      0      0      0      0      1  \n",
       "5436           23      0      0      0      0      0      0      1  \n",
       "5437           18      1      0      0      0      0      0      0  \n",
       "\n",
       "[5438 rows x 1211 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98a05180-ce92-40ea-a5ef-43496139e193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "personality_columns = ['Openness', 'Agreeableness', 'Conscientiousness', 'Extraversion', 'Neuroticism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f87c9f83-6be6-4be6-bbba-d3e33664ae9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tabular.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cac29f0-ca1c-4e17-bd33-0559de745689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_ids = tabular['Pcode'].unique()\n",
    "random.seed(150)   \n",
    "test_ids = np.random.choice(unique_ids, 15, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e23e8bc-40f9-487c-bdb0-4760cb0134a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_count_row = p_code_counts.loc[p_code_counts['counts'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63391fb7-2a2d-4582-a5e1-d9bec6d71a67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pcode     P75\n",
       "counts    109\n",
       "Name: 69, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_count_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35facb71-b180-4ed2-a026-d9eccd615e94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data= tabular[tabular['Pcode'].isin(test_ids)]\n",
    "train_data= tabular[~tabular['Pcode'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b2d8072-e50d-4596-a54d-663bfc97448c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_dataframe(df):\n",
    "    # Encode the Gender column\n",
    "    if 'Gender' in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df['Gender'] = le.fit_transform(df['Gender'])\n",
    "\n",
    "    # Convert object columns to category if needed\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def scale_numeric_columns(df_train, df_test, exclude_columns):\n",
    "    # Identify numeric columns\n",
    "    numeric_cols = df_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "    # Exclude specified columns from numeric columns\n",
    "    numeric_cols = [col for col in numeric_cols if col not in exclude_columns]\n",
    "\n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the scaler on the training data and transform the training data\n",
    "    df_train_scaled = df_train.copy()\n",
    "    df_train_scaled[numeric_cols] = scaler.fit_transform(df_train[numeric_cols])\n",
    "\n",
    "    # Transform the test data using the same scaler\n",
    "    df_test_scaled = df_test.copy()\n",
    "    df_test_scaled[numeric_cols] = scaler.transform(df_test[numeric_cols])\n",
    "\n",
    "    return df_train_scaled, df_test_scaled\n",
    "\n",
    "def create_personality_flags(df, personality_columns):\n",
    "    for col in personality_columns:\n",
    "        df[f'{col}_High'] = (df[col] >= 9).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0e458aa-194e-4e4d-a058-3fa3f0e21d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, test_data = scale_numeric_columns(\n",
    "    train_data, test_data, ['Stress_binary', 'Valence_binary', 'Arousal_binary', 'day_0', 'day_1', 'day_2', 'day_3', 'day_4', 'day_5', 'day_6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9f106f2-2a0e-44a8-ad2c-9b9da2ee05a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SVMGroupKFoldCV(data, train, test, unique_ids, test_ids, idcolumn, outcomevar, dropcols=[], n_splits=5, n_jobs=-1):\n",
    "   \n",
    "    train_data = encode_dataframe(train.copy())\n",
    "    test_data = encode_dataframe(test.copy())\n",
    "    \n",
    "    best_hyperparams = []\n",
    "    F1 = []\n",
    "\n",
    "    group_kfold = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    param_dist = {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'kernel': ['rbf']\n",
    "    }\n",
    "\n",
    "    # Step 2: Perform GroupKFold on the remaining data\n",
    "    best_f1_score = -1  # Initialize to a very low value\n",
    "    best_params_overall = None\n",
    "\n",
    "    for train_index, val_index in group_kfold.split(train_data, groups=train_data[idcolumn]):\n",
    "        data_train = train_data.iloc[train_index]\n",
    "        data_val = train_data.iloc[val_index]\n",
    "\n",
    "        svm = SVC(probability = True, random_state=0)\n",
    "        random_search = RandomizedSearchCV(svm, param_dist, cv=3, scoring='f1_macro', n_jobs=n_jobs, random_state= 0, n_iter= 10)\n",
    "        random_search.fit(data_train.drop(columns=dropcols + [outcomevar]), data_train[outcomevar])\n",
    "\n",
    "        best_params = random_search.best_params_\n",
    "        best_hyperparams.append(best_params)\n",
    "\n",
    "        svm_best = SVC(**best_params, probability = True , random_state=0)\n",
    "        svm_best.fit(data_train.drop(columns=dropcols + [outcomevar]), data_train[outcomevar])\n",
    "\n",
    "        predictions = svm_best.predict(data_val.drop(columns=dropcols + [outcomevar]))\n",
    "        f1 = f1_score(data_val[outcomevar], predictions, average='macro')\n",
    "        F1.append(f1)\n",
    "\n",
    "        if f1 > best_f1_score:\n",
    "            best_f1_score = f1\n",
    "            best_params_overall = best_params\n",
    "\n",
    "        print('...Fold processing complete.')\n",
    "\n",
    "    mean_F1_micro = np.mean(F1)\n",
    "    std_F1_micro = np.std(F1)\n",
    "\n",
    "    # Use the best hyperparameters to train the final model\n",
    "    final_model = SVC(**best_params_overall, probability= True , random_state=0)\n",
    "    final_model.fit(train_data.drop(columns=dropcols + [outcomevar]), train_data[outcomevar])\n",
    "\n",
    "    # Predict on the separate test set\n",
    "    test_predictions = final_model.predict(test_data.drop(columns=dropcols + [outcomevar]))\n",
    "    test_F1_score = f1_score(test_data[outcomevar], test_predictions, average='macro')\n",
    "    test_confusion_matrix = confusion_matrix(test_data[outcomevar], test_predictions)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f'Mean F1 (Overall): {mean_F1_micro}')\n",
    "    print(f'Std F1 (Overall): {std_F1_micro}')\n",
    "    print(f'Test F1 Score (Overall): {test_F1_score}')\n",
    "\n",
    "    # Print confusion matrices\n",
    "    print('Overall Confusion Matrix:')\n",
    "    print(test_confusion_matrix)\n",
    "\n",
    "    # Compute permutation feature importance\n",
    "    # result = permutation_importance(final_model, test_data.drop(columns=dropcols + [outcomevar]), test_data[outcomevar], n_repeats=10, random_state=42, n_jobs=n_jobs)\n",
    "    # for i in result.importances_mean.argsort()[::-1]:\n",
    "    #     print(f\"{test_data.columns[i]}: {result.importances_mean[i]:.4f} +/- {result.importances_std[i]:.4f}\")\n",
    "\n",
    "    # Optionally, compute SHAP values (can be commented out if causing kernel restarts)\n",
    "    # try:\n",
    "    #     explainer = shap.KernelExplainer(final_model.predict_proba, train_data.drop(columns=dropcols + [outcomevar])[:100])\n",
    "    #     shap_values = explainer.shap_values(test_data.drop(columns=dropcols + [outcomevar])[:50])\n",
    "    #     shap.summary_plot(shap_values, test_data.drop(columns=dropcols + [outcomevar])[:50], feature_names=test_data.drop(columns=dropcols + [outcomevar]).columns)\n",
    "    # except Exception as e:\n",
    "    #     print(f\"SHAP computation failed: {e}\")\n",
    "    \n",
    "    print(best_params_overall)\n",
    "\n",
    "    # Return results\n",
    "    return mean_F1_micro, std_F1_micro, test_F1_score, test_confusion_matrix, best_params_overall, final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "737aa8c5-f87a-404b-8629-63f16a2988e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fold processing complete.\n",
      "...Fold processing complete.\n",
      "...Fold processing complete.\n",
      "...Fold processing complete.\n",
      "...Fold processing complete.\n",
      "Mean F1 (Overall): 0.5174945695474259\n",
      "Std F1 (Overall): 0.010472406427535799\n",
      "Test F1 Score (Overall): 0.5010227775320655\n",
      "Overall Confusion Matrix:\n",
      "[[382 171]\n",
      " [357 184]]\n",
      "{'kernel': 'rbf', 'gamma': 'auto', 'C': 1}\n"
     ]
    }
   ],
   "source": [
    "mean_f1, std_f1, test_f1, test_cm, best_params, final_model = SVMGroupKFoldCV(\n",
    "    data = tabular, \n",
    "    train = train_data, \n",
    "    test = test_data, \n",
    "    unique_ids = unique_ids, \n",
    "    test_ids = test_ids, \n",
    "    idcolumn = 'Pcode',\n",
    "    outcomevar = 'Stress_binary',\n",
    "    dropcols=['Pcode', 'ResponseTime', 'Valence_binary', 'Arousal_binary'], n_splits=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b7f3f80-0498-4269-9376-9293a7385b28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fold processing complete.\n",
      "...Fold processing complete.\n",
      "...Fold processing complete.\n",
      "...Fold processing complete.\n",
      "...Fold processing complete.\n",
      "Mean F1 (Overall): 0.5395309664576053\n",
      "Std F1 (Overall): 0.02629201132687472\n",
      "Test F1 Score (Overall): 0.5173523733557334\n",
      "Overall Confusion Matrix:\n",
      "[[171 298]\n",
      " [202 423]]\n",
      "{'kernel': 'rbf', 'gamma': 'scale', 'C': 1}\n"
     ]
    }
   ],
   "source": [
    "mean_f1_valence, std_f1_valence, test_f1_valence, test_cm_valence, best_params_valence, final_model_valence = SVMGroupKFoldCV(\n",
    "    data = tabular, \n",
    "    train = train_data, \n",
    "    test = test_data, \n",
    "    unique_ids = unique_ids, \n",
    "    test_ids = test_ids, \n",
    "    idcolumn = 'Pcode',\n",
    "    outcomevar = 'Valence_binary',\n",
    "    dropcols=['Pcode', 'ResponseTime', 'Stress_binary', 'Arousal_binary'], n_splits=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e5dcb48-37f0-4df7-a8d7-12e07b6a3003",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Fold processing complete.\n",
      "...Fold processing complete.\n",
      "...Fold processing complete.\n",
      "...Fold processing complete.\n",
      "...Fold processing complete.\n",
      "Mean F1 (Overall): 0.5607464868416526\n",
      "Std F1 (Overall): 0.027269662052613133\n",
      "Test F1 Score (Overall): 0.574404026940993\n",
      "Overall Confusion Matrix:\n",
      "[[377 233]\n",
      " [227 257]]\n",
      "{'kernel': 'rbf', 'gamma': 'scale', 'C': 1}\n"
     ]
    }
   ],
   "source": [
    "mean_f1_arousal, std_f1_arousal, test_f1_arousal, test_cm_arousal, best_params_arousal, final_model_arousal = SVMGroupKFoldCV(\n",
    "    data = tabular, \n",
    "    train = train_data, \n",
    "    test = test_data, \n",
    "    unique_ids = unique_ids, \n",
    "    test_ids = test_ids, \n",
    "    idcolumn = 'Pcode',\n",
    "    outcomevar = 'Arousal_binary',\n",
    "    dropcols=['Pcode', 'ResponseTime', 'Stress_binary', 'Valence_binary'], n_splits=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd6c41c-ff87-497f-99c7-c418e227715b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
