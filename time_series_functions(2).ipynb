{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d8a1dbd-fe7b-4f1a-9e32-264cdb0011a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_message_time_series(df, windows, timestamp):\n",
    "    windowed_messageevent = {}\n",
    "\n",
    "    # If the DataFrame is empty, return a dictionary with zeros\n",
    "    if df.empty:\n",
    "        for i in range(25):  # Assuming 49 timesteps\n",
    "            windowed_messageevent[timestamp - pd.Timedelta(minutes=30) * i] = [0, 0, 0, 0, 0]\n",
    "        return windowed_messageevent\n",
    "\n",
    "    # Process the DataFrame if it's not empty\n",
    "    before_esm = df[df.index <= timestamp]\n",
    "    timestamp = pd.Timestamp(timestamp)\n",
    "    end_time = timestamp\n",
    "    max_timestamp = max(before_esm.index.min(), timestamp - pd.Timedelta(hours=12))\n",
    "\n",
    "    current_time = end_time  # Start from the end_time\n",
    "    while current_time >= max_timestamp - pd.Timedelta(minutes=30):  # Iterate backwards\n",
    "        window_start = current_time - pd.Timedelta(minutes=30)\n",
    "        windowed_data = before_esm[(before_esm.index >= window_start) & (before_esm.index < current_time)]\n",
    "\n",
    "        if current_time >= max_timestamp:\n",
    "            if not windowed_data.empty:\n",
    "                unique_numbers_outgoing = []\n",
    "                unique_numbers_incoming = []\n",
    "                messages_outgoing = 0\n",
    "                messages_incoming = 0 \n",
    "                unique_messegers_outgoing = 0\n",
    "                unique_messegers_incoming = 0 \n",
    "                total_messages = 0 \n",
    "                for message_time, message_type, number, in windowed_data[['messageBox', 'number']].itertuples(index=True):\n",
    "                    total_messages += 1\n",
    "                    if message_type == 'SENT':\n",
    "                        messages_outgoing += 1\n",
    "                        if number not in unique_numbers_outgoing:\n",
    "                            unique_messegers_outgoing += 1\n",
    "                            unique_numbers_outgoing.append(number)\n",
    "                    elif message_type == 'INBOX':\n",
    "                        messages_incoming += 1\n",
    "                        if number not in unique_numbers_incoming:\n",
    "                            unique_messegers_incoming += 1\n",
    "                            unique_numbers_incoming.append(number)\n",
    "                windowed_messageevent[current_time] = [messages_outgoing, messages_incoming, unique_messegers_outgoing, unique_messegers_incoming, total_messages]\n",
    "            else:\n",
    "                windowed_messageevent[current_time] = [0, 0, 0, 0, 0]  # Default values if no data in the window\n",
    "        else:\n",
    "            windowed_messageevent[current_time] = [-1999, -1999, -1999, -1999, -1999]  # Padding with -1999 when out of range\n",
    "\n",
    "        current_time -= pd.Timedelta(minutes=30)  # Decrement current_time\n",
    "\n",
    "    # Ensure all 49 timesteps are covered\n",
    "    current_time = end_time  # Reset current_time to end_time\n",
    "    for i in range(25):\n",
    "        timestep_timestamp = timestamp - pd.Timedelta(minutes=30) * i\n",
    "        if timestep_timestamp not in windowed_messageevent:\n",
    "            if timestep_timestamp > end_time:\n",
    "                windowed_messageevent[timestep_timestamp] = [0, 0, 0, 0, 0]\n",
    "            elif timestep_timestamp < max_timestamp:\n",
    "                windowed_messageevent[timestep_timestamp] = [-1999, -1999, -1999, -1999, -1999]\n",
    "            else:\n",
    "                windowed_messageevent[timestep_timestamp] = [0, 0, 0, 0, 0]\n",
    "\n",
    "    return windowed_messageevent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57aff6be-866d-4e0b-8912-55d32b9cc7d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_deviceevent_time_series(df, windows, timestamp):\n",
    "    windowed_deviceevent = {}\n",
    "    \n",
    "    if df.empty:\n",
    "        for i in range(25):  # Assuming 49 timesteps\n",
    "            windowed_deviceevent[timestamp - pd.Timedelta(minutes=30) * i] = [-1999, -1999]\n",
    "        return windowed_deviceevent\n",
    "\n",
    "    before_esm = df[df.index <= timestamp]\n",
    "    timestamp = pd.Timestamp(timestamp)\n",
    "    end_time = timestamp\n",
    "    max_timestamp = max(before_esm.index.min(), timestamp - pd.Timedelta(hours=12))\n",
    "\n",
    "    current_time = end_time  # Start from the end_time\n",
    "    while current_time >= max_timestamp - pd.Timedelta(minutes=30):  # Iterate backwards\n",
    "        window_size = windows['30min']  # Retrieve window size from the windows dictionary\n",
    "        window_start = current_time - pd.Timedelta(minutes=30)\n",
    "        windowed_data = before_esm[(before_esm.index >= window_start) & (before_esm.index < current_time)]\n",
    "\n",
    "        if current_time >= max_timestamp:\n",
    "            times_unlocked = 0\n",
    "            time_spent_on_phone = 0\n",
    "            unlock_time = None  # Variable to store the timestamp of the last unlock event\n",
    "\n",
    "            for _, event_type in windowed_data[['type']].itertuples(index=True):\n",
    "                if event_type == 'UNLOCK':\n",
    "                    times_unlocked += 1\n",
    "                    unlock_time = current_time  # Update the unlock time\n",
    "                elif event_type == 'SCREEN_OFF' and unlock_time is not None:\n",
    "                    # Calculate the time spent on phone by subtracting unlock time from screen off time\n",
    "                    time_spent_on_phone += 30 * 60  # Assuming 10 minutes window size\n",
    "                    unlock_time = None  # Reset the unlock time\n",
    "\n",
    "            proportion_time_spent_on_phone = time_spent_on_phone / window_size\n",
    "            windowed_deviceevent[current_time] = [times_unlocked, proportion_time_spent_on_phone]\n",
    "        else:\n",
    "            windowed_deviceevent[current_time] = [-1999, -1999]  # Padding with -1999 when out of range\n",
    "\n",
    "        current_time -= pd.Timedelta(minutes=30)  # Decrement current_time\n",
    "\n",
    "    # Ensure all 49 timesteps are covered\n",
    "    for i in range(25):\n",
    "        timestep_timestamp = timestamp - pd.Timedelta(minutes=30) * i\n",
    "        if timestep_timestamp not in windowed_deviceevent:\n",
    "            if timestep_timestamp > end_time:\n",
    "                windowed_deviceevent[timestep_timestamp] = [-1999, -1999]\n",
    "            elif timestep_timestamp < max_timestamp:\n",
    "                windowed_deviceevent[timestep_timestamp] = [-1999, -1999]\n",
    "            else:\n",
    "                windowed_deviceevent[timestep_timestamp] = [-1999, -1999]\n",
    "\n",
    "    return windowed_deviceevent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e21ad89-d962-4f05-bef0-45fc839a0691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def entropy(labels):\n",
    "    n_labels = len(labels)\n",
    "    \n",
    "    if n_labels <= 1:\n",
    "        return 0\n",
    "    \n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    probs = counts / n_labels\n",
    "    entropy = -np.sum(probs * np.log2(probs))\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "\n",
    "def extract_appusage_time_series(df, windows, timestamp):\n",
    "    windowed_appevent = {}\n",
    "    \n",
    "    if df.empty:\n",
    "        for i in range(25):  # Assuming 49 timesteps\n",
    "            windowed_appevent[timestamp - pd.Timedelta(minutes=30) * i] = [-1999] * 17  # Adjusting size to 17 to match expected output\n",
    "        return windowed_appevent\n",
    "\n",
    "    before_esm = df[df.index <= timestamp]\n",
    "    timestamp = pd.Timestamp(timestamp)\n",
    "    end_time = timestamp\n",
    "    max_timestamp = max(before_esm.index.min(), timestamp - pd.Timedelta(hours=12))\n",
    "\n",
    "    current_time = end_time  # Start from the end_time\n",
    "\n",
    "    while current_time >= max_timestamp:  # Iterate backwards\n",
    "        window_start = current_time - pd.Timedelta(minutes=30)\n",
    "\n",
    "        if window_start < df.index.min():\n",
    "            windowed_appevent[current_time] = [-1999] * 17  # Out of range, fill with -1999\n",
    "        else:\n",
    "            windowed_data = before_esm[(before_esm.index >= window_start) & (before_esm.index <= current_time)]\n",
    "            \n",
    "            sequence_data = [0] * 17  # Placeholder for all variables with zeros\n",
    "\n",
    "            if not windowed_data.empty:\n",
    "                # Find the top 5 categories\n",
    "                top_categories = list(windowed_data['category'].value_counts().head(5).index)\n",
    "                \n",
    "                # If there are fewer than 5 categories, fill the remaining slots with NaN\n",
    "                top_categories.extend([np.nan] * (5 - len(top_categories)))\n",
    "                \n",
    "                # Fill in category names\n",
    "                sequence_data[:5] = top_categories\n",
    "                \n",
    "                # Calculate statistics for observed categories\n",
    "                for i, category in enumerate(top_categories):\n",
    "                    if pd.isna(category):\n",
    "                        continue\n",
    "                    category_data = windowed_data[windowed_data['category'] == category]\n",
    "                    move_to_foreground_indices = category_data[category_data['type'] == 'MOVE_TO_FOREGROUND'].index\n",
    "                    move_to_background_indices = category_data[category_data['type'] == 'MOVE_TO_BACKGROUND'].index\n",
    "\n",
    "                    category_time_spent = 0\n",
    "                    for foreground_index in move_to_foreground_indices:\n",
    "                        next_background_index = min(move_to_background_indices[move_to_background_indices > foreground_index], default=None)\n",
    "                        if next_background_index is not None:\n",
    "                            category_time_spent += (next_background_index - foreground_index).total_seconds()\n",
    "\n",
    "                    # Fill in actual values for observed categories\n",
    "                    sequence_data[5 + i] = category_time_spent / 60  # Time spent in minutes\n",
    "                    sequence_data[10 + i] = len(category_data)  # Count of events\n",
    "\n",
    "                # Calculate entropy and add most common category\n",
    "                app_category_entropy = entropy(windowed_data['category'].value_counts())\n",
    "                most_common_category = windowed_data['category'].mode().iloc[0]\n",
    "                sequence_data[15] = app_category_entropy\n",
    "                sequence_data[16] = most_common_category\n",
    "\n",
    "            windowed_appevent[current_time] = sequence_data\n",
    "        \n",
    "        current_time -= pd.Timedelta(minutes=30)  # Decrement current_time\n",
    "\n",
    "    # Ensure all 49 timesteps are covered\n",
    "    for i in range(25):\n",
    "        timestep_timestamp = timestamp - pd.Timedelta(minutes=30) * i\n",
    "        if timestep_timestamp not in windowed_appevent:\n",
    "            if timestep_timestamp > end_time:\n",
    "                windowed_appevent[timestep_timestamp] = [0] * 17\n",
    "            else:\n",
    "                windowed_appevent[timestep_timestamp] = [-1999] * 17\n",
    "\n",
    "    return windowed_appevent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b4adbfb-17a1-4ba2-8392-f3c7c46361df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_call_timeseries(df, windows, timestamp):\n",
    "    windowed_callevent = {}\n",
    "    \n",
    "    if df.empty:\n",
    "        for i in range(25):  # Assuming 49 timesteps\n",
    "            windowed_callevent[timestamp - pd.Timedelta(minutes=30) * i] = [-1999, -1999, -1999]\n",
    "        return windowed_callevent\n",
    "\n",
    "    before_esm = df[df.index <= timestamp]\n",
    "    timestamp = pd.Timestamp(timestamp)\n",
    "    end_time = timestamp\n",
    "    max_timestamp = max(before_esm.index.min(), timestamp - pd.Timedelta(hours=12))\n",
    "\n",
    "    current_time = end_time  # Start from the end_time\n",
    "    while current_time >= max_timestamp - pd.Timedelta(minutes=30):  # Iterate backwards\n",
    "        window_start = current_time - pd.Timedelta(minutes=30)\n",
    "        windowed_data = before_esm[(before_esm.index >= window_start) & (before_esm.index < current_time)]\n",
    "\n",
    "        if current_time >= max_timestamp:\n",
    "            unique_callers_outgoing = set()\n",
    "            unique_callers_incoming = set()\n",
    "            time_spent_calling = 0\n",
    "\n",
    "            for _, row in windowed_data.iterrows():\n",
    "                call_type = row['type']\n",
    "                number = row['number']\n",
    "                duration = row['duration']\n",
    "                time_spent_calling += duration / 60  # Accumulate duration in minutes\n",
    "                if call_type == 'OUTGOING':\n",
    "                    unique_callers_outgoing.add(number)\n",
    "                elif call_type == 'INCOMING':\n",
    "                    unique_callers_incoming.add(number)\n",
    "\n",
    "            windowed_callevent[current_time] = [len(unique_callers_outgoing), len(unique_callers_incoming), time_spent_calling]\n",
    "        else:\n",
    "            windowed_callevent[current_time] = [-1999, -1999, -1999]  # Padding with -1999 when out of range\n",
    "\n",
    "        current_time -= pd.Timedelta(minutes=30)  # Decrement current_time\n",
    "\n",
    "    # Ensure all 49 timesteps are covered\n",
    "    for i in range(25):\n",
    "        timestep_timestamp = timestamp - pd.Timedelta(minutes=30) * i\n",
    "        if timestep_timestamp not in windowed_callevent:\n",
    "            if timestep_timestamp > end_time:\n",
    "                windowed_callevent[timestep_timestamp] = [-1999, -1999, -1999]\n",
    "            elif timestep_timestamp < max_timestamp:\n",
    "                windowed_callevent[timestep_timestamp] = [-1999, -1999, -1999]\n",
    "            else:\n",
    "                windowed_callevent[timestep_timestamp] = [-1999, -1999, -1999]\n",
    "\n",
    "    return windowed_callevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fe54c3e-6ffa-48a4-bf75-2ebc789710ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Location.csv\n",
    "def calculate_entropy(cluster_counts):\n",
    "    total_time = cluster_counts.sum()\n",
    "    cluster_proportions = cluster_counts / total_time\n",
    "    entropy = -np.sum([p * np.log2(p) for p in cluster_proportions.values if p != 0])\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def extract_location_time_series(df, windows, timestamp):\n",
    "    windowed_location = {}\n",
    "\n",
    "    if df.empty:\n",
    "        for i in range(25):  # Assuming 49 timesteps\n",
    "            windowed_location[timestamp - pd.Timedelta(minutes=30) * i] = [-1999, -1999]\n",
    "        return windowed_location\n",
    "\n",
    "    before_esm = df[df.index <= timestamp]\n",
    "    timestamp = pd.Timestamp(timestamp)\n",
    "    end_time = timestamp\n",
    "    max_timestamp = max(before_esm.index.min(), timestamp - pd.Timedelta(hours=12))\n",
    "\n",
    "    current_time = end_time  # Start from the end_time\n",
    "    while current_time >= max_timestamp - pd.Timedelta(minutes=30):  # Iterate backwards\n",
    "        window_start = current_time - pd.Timedelta(minutes=30)\n",
    "        windowed_data = before_esm[(before_esm.index >= window_start) & (before_esm.index < current_time)]\n",
    "\n",
    "        if current_time >= max_timestamp:\n",
    "            if len(windowed_data) == 0:\n",
    "                most_common_cluster = np.nan\n",
    "                window_entropy = np.nan\n",
    "                window_normalised_entropy = np.nan\n",
    "            else:\n",
    "                cluster_counts = windowed_data['cluster'].value_counts()\n",
    "                most_common_cluster = windowed_data['cluster'].mode().iloc[0]\n",
    "                window_entropy = calculate_entropy(cluster_counts)\n",
    "                window_normalised_entropy = calculate_normalised_entropy(cluster_counts)\n",
    "\n",
    "            windowed_location[current_time] = [most_common_cluster, window_entropy]\n",
    "        else:\n",
    "            windowed_location[current_time] = [-1999, -1999]  # Padding with -1999 when out of range\n",
    "\n",
    "        current_time -= pd.Timedelta(minutes=30)  # Decrement current_time\n",
    "\n",
    "    # Ensure all 49 timesteps are covered\n",
    "    for i in range(25):\n",
    "        timestep_timestamp = timestamp - pd.Timedelta(minutes=30) * i\n",
    "        if timestep_timestamp not in windowed_location:\n",
    "            if timestep_timestamp > end_time:\n",
    "                windowed_location[timestep_timestamp] = [-1999, -1999]\n",
    "            elif timestep_timestamp < max_timestamp:\n",
    "                windowed_location[timestep_timestamp] = [-1999, -1999]\n",
    "            else:\n",
    "                windowed_location[timestep_timestamp] = [-1999, -1999]\n",
    "\n",
    "    return windowed_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95d568a8-c465-4004-8424-1b7cd9dc4aff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generic_entropy(data):\n",
    "    value_counts = data.value_counts()\n",
    "    probabilities = value_counts / len(data)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n",
    "\n",
    "def extract_generic_time_series(df, windows, timestamp):\n",
    "    windowed_features_dict = {}\n",
    "    timestamp = pd.Timestamp(timestamp)\n",
    "    \n",
    "    # If the DataFrame is empty, return a dictionary with zeros\n",
    "    if df.empty:\n",
    "        for i in range(25):  # Assuming 25 timesteps\n",
    "            windowed_features_dict[timestamp - pd.Timedelta(minutes=30) * i] = [0, 0, 0, 0]\n",
    "        return windowed_features_dict\n",
    "\n",
    "    # Process the DataFrame if it's not empty\n",
    "    before_esm = df[df.index <= timestamp]\n",
    "    end_time = timestamp\n",
    "    max_timestamp = max(before_esm.index.min(), timestamp - pd.Timedelta(hours=12))\n",
    "\n",
    "    current_time = end_time  # Start from the end_time\n",
    "    while current_time >= max_timestamp:  # Iterate backwards\n",
    "        window_start = current_time - pd.Timedelta(minutes=30)\n",
    "        windowed_data = before_esm[(before_esm.index >= window_start) & (before_esm.index < current_time)]\n",
    "\n",
    "        windowed_features = []  # Initialize list to store statistics for each column\n",
    "        if not windowed_data.empty:\n",
    "            numeric_cols = windowed_data.select_dtypes(include=np.number).columns\n",
    "            for col in numeric_cols:\n",
    "                col_mean = windowed_data[col].mean()\n",
    "                col_median = windowed_data[col].median()\n",
    "                col_std = windowed_data[col].std()\n",
    "                col_entropy = generic_entropy(windowed_data[col])\n",
    "                windowed_features.extend([col_mean, col_median, col_std, col_entropy])  # Extend the list with statistics\n",
    "        else:\n",
    "            numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "            windowed_features = [np.nan, np.nan, np.nan, np.nan] * len(numeric_cols)\n",
    "        \n",
    "        windowed_features_dict[current_time] = windowed_features\n",
    "\n",
    "        current_time -= pd.Timedelta(minutes=30)  # Decrement current_time\n",
    "\n",
    "    # Ensure all 25 timesteps are covered\n",
    "    for i in range(25):\n",
    "        timestep_timestamp = timestamp - pd.Timedelta(minutes=30) * i\n",
    "        if timestep_timestamp not in windowed_features_dict:\n",
    "            numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "            if timestep_timestamp > end_time:\n",
    "                windowed_features_dict[timestep_timestamp] = [0, 0, 0, 0] * len(numeric_cols)\n",
    "            elif timestep_timestamp < max_timestamp:\n",
    "                windowed_features_dict[timestep_timestamp] = [-1999, -1999, -1999, -1999] * len(numeric_cols)\n",
    "            else:\n",
    "                windowed_features_dict[timestep_timestamp] = [0, 0, 0, 0] * len(numeric_cols)\n",
    "\n",
    "    return windowed_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0e052d4-6351-4fe6-bca0-fb2e352d6913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sequence_creation(all_participants_data, esm_responses, user_info):\n",
    "#     desired_structure = {}\n",
    "#     days_of_week = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    \n",
    "#     window = {'30min': 60 * 30}\n",
    "    \n",
    "#     # Preprocess user_info to avoid repeated lookups\n",
    "#     user_info_dict = user_info.set_index('Pcode').to_dict(orient='index')\n",
    "    \n",
    "#     # Preprocess external functions\n",
    "#     external_functions = [\n",
    "#         (extract_generic_time_series, 'Calorie.csv'),\n",
    "#         (extract_generic_time_series, 'SkinTemperature.csv'),\n",
    "#         (extract_generic_time_series, 'AmbientLight.csv'),\n",
    "#         (extract_generic_time_series, 'RRI.csv'),\n",
    "#         (extract_generic_time_series, 'StepCount.csv'),\n",
    "#         (extract_message_time_series, 'MessageEvent.csv'),\n",
    "#         (extract_call_timeseries, 'CallEvent.csv'),\n",
    "#         (extract_generic_time_series, 'ActivityEvent.csv'),\n",
    "#         (extract_location_time_series, 'Location.csv'),\n",
    "#         (extract_generic_time_series, 'HR.csv'),\n",
    "#         (extract_generic_time_series, 'Distance.csv'),\n",
    "#         (extract_appusage_time_series, 'AppUsageEvent.csv'),\n",
    "#         (extract_generic_time_series, 'Acceleration.csv'),\n",
    "#         (extract_generic_time_series, 'UltraViolet.csv'),\n",
    "#         (extract_deviceevent_time_series, 'DeviceEvent.csv')\n",
    "#     ]\n",
    "    \n",
    "#     for participant_id, participant_data in all_participants_data.items():\n",
    "#         sleep_proxies = participant_data['sleep_proxies']\n",
    "\n",
    "#         participant_esm_responses = esm_responses[esm_responses['Pcode'] == participant_id]\n",
    "#         for index, esm_response in participant_esm_responses.iterrows():\n",
    "#             timestamp = pd.Timestamp(esm_response['ResponseTime'])\n",
    "#             sequence_name = f\"{timestamp}_{index}\"\n",
    "#             day_of_week = days_of_week[timestamp.weekday()]\n",
    "#             user_info_row = user_info_dict.get(participant_id, {})\n",
    "#             static_features = [day_of_week, user_info_row.get('Age', 0), user_info_row.get('Gender', ''), \n",
    "#                                user_info_row.get('Openness', 0), user_info_row.get('Conscientiousness', 0),\n",
    "#                                user_info_row.get('Neuroticism', 0), user_info_row.get('Extraversion', 0),\n",
    "#                                user_info_row.get('Agreeableness', 0), user_info_row.get('PSS10', 0),\n",
    "#                                user_info_row.get('PHQ9', 0), user_info_row.get('GHQ12', 0)]\n",
    "            \n",
    "            \n",
    "#             date_of_timestamp = timestamp.date()  # Normalize to date without time\n",
    "#             if date_of_timestamp in sleep_proxies.index:\n",
    "#                 sleep_proxy_for_timestamp = sleep_proxies.loc[date_of_timestamp, 'SleepProxy']\n",
    "#                 sleep_proxy_hours = sleep_proxy_for_timestamp.total_seconds() / 3600\n",
    "#                 static_features.append(sleep_proxy_hours)\n",
    "#             else:\n",
    "#                 static_features.append(0)  # Appending 0 if there's no sleep proxy data\n",
    "\n",
    "\n",
    "#             # Initialize desired structure with 49 timesteps\n",
    "#             timestep_features = [[] for _ in range(25)]\n",
    "#             for func, dataframe_name in external_functions:\n",
    "#                 dataframe = participant_data.get(dataframe_name)\n",
    "#                 if dataframe is not None:\n",
    "#                     timestep_features_func = func(dataframe, window, timestamp)\n",
    "#                     for i in range(25):\n",
    "#                         timestep_timestamp = timestamp - pd.Timedelta(minutes=30) * i\n",
    "#                         if timestep_timestamp in timestep_features_func:\n",
    "#                             timestep_features[i].extend(timestep_features_func[timestep_timestamp])\n",
    "\n",
    "#             desired_structure.setdefault(participant_id, {}).setdefault(sequence_name, {\n",
    "#                 'features': [static_features + timestep for timestep in timestep_features],\n",
    "#                 'target': [esm_response['Stress_binary'], esm_response['Valence_binary'], esm_response['Arousal_binary']]\n",
    "#             })\n",
    "\n",
    "#     return desired_structure\n",
    "\n",
    "def sequence_creation(all_participants_data, esm_responses, user_info):\n",
    "    desired_structure = {}\n",
    "    days_of_week = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    \n",
    "    window = {'30min': 60 * 30}\n",
    "    \n",
    "    # Preprocess user_info to avoid repeated lookups\n",
    "    user_info_dict = user_info.set_index('Pcode').to_dict(orient='index')\n",
    "    \n",
    "    # Preprocess external functions\n",
    "    external_functions = [\n",
    "        (extract_generic_time_series, 'Calorie.csv'),\n",
    "        (extract_generic_time_series, 'SkinTemperature.csv'),\n",
    "        (extract_generic_time_series, 'AmbientLight.csv'),\n",
    "        (extract_generic_time_series, 'RRI.csv'),\n",
    "        (extract_generic_time_series, 'StepCount.csv'),\n",
    "        (extract_message_time_series, 'MessageEvent.csv'),\n",
    "        (extract_call_timeseries, 'CallEvent.csv'),\n",
    "        (extract_generic_time_series, 'ActivityEvent.csv'),\n",
    "        (extract_location_time_series, 'Location.csv'),\n",
    "        (extract_generic_time_series, 'HR.csv'),\n",
    "        (extract_generic_time_series, 'Distance.csv'),\n",
    "        (extract_appusage_time_series, 'AppUsageEvent.csv'),\n",
    "        (extract_generic_time_series, 'Acceleration.csv'),\n",
    "        (extract_generic_time_series, 'UltraViolet.csv'),\n",
    "        (extract_deviceevent_time_series, 'DeviceEvent.csv')\n",
    "    ]\n",
    "    \n",
    "    for participant_id, participant_data in all_participants_data.items():\n",
    "        sleep_proxies = participant_data['sleep_proxies']\n",
    "\n",
    "        participant_esm_responses = esm_responses[esm_responses['Pcode'] == participant_id]\n",
    "        for index, esm_response in participant_esm_responses.iterrows():\n",
    "            timestamp = pd.Timestamp(esm_response['ResponseTime'])\n",
    "            sequence_name = f\"{timestamp}_{index}\"\n",
    "            day_of_week = days_of_week[timestamp.weekday()]\n",
    "            user_info_row = user_info_dict.get(participant_id, {})\n",
    "            static_features = [day_of_week, user_info_row.get('Age', 0), user_info_row.get('Gender', ''), \n",
    "                               user_info_row.get('Openness', 0), user_info_row.get('Conscientiousness', 0),\n",
    "                               user_info_row.get('Neuroticism', 0), user_info_row.get('Extraversion', 0),\n",
    "                               user_info_row.get('Agreeableness', 0), user_info_row.get('PSS10', 0),\n",
    "                               user_info_row.get('PHQ9', 0), user_info_row.get('GHQ12', 0)]\n",
    "            \n",
    "            date_of_timestamp = timestamp.date()  # Normalize to date without time\n",
    "            if date_of_timestamp in sleep_proxies.index:\n",
    "                sleep_proxy_for_timestamp = sleep_proxies.loc[date_of_timestamp, 'SleepProxy']\n",
    "                sleep_proxy_hours = sleep_proxy_for_timestamp.total_seconds() / 3600\n",
    "                static_features.append(sleep_proxy_hours)\n",
    "            else:\n",
    "                static_features.append(0)  # Appending 0 if there's no sleep proxy data\n",
    "\n",
    "            # Initialize desired structure with 25 timesteps\n",
    "            timestep_features = [[] for _ in range(25)]\n",
    "            feature_counts = {df_name: 0 for _, df_name in external_functions}  # Initialize feature count dictionary\n",
    "            \n",
    "            for func, dataframe_name in external_functions:\n",
    "                dataframe = participant_data.get(dataframe_name)\n",
    "                if dataframe is not None:\n",
    "                    timestep_features_func = func(dataframe, window, timestamp)\n",
    "                    for i in range(25):\n",
    "                        timestep_timestamp = timestamp - pd.Timedelta(minutes=30) * i\n",
    "                        if timestep_timestamp in timestep_features_func:\n",
    "                            extracted_features = timestep_features_func[timestep_timestamp]\n",
    "                            timestep_features[i].extend(extracted_features)\n",
    "                            feature_counts[dataframe_name] += len(extracted_features)  # Count features added\n",
    "\n",
    "            desired_structure.setdefault(participant_id, {}).setdefault(sequence_name, {\n",
    "                'features': [static_features + timestep for timestep in timestep_features],\n",
    "                'target': [esm_response['Stress_binary'], esm_response['Valence_binary'], esm_response['Arousal_binary']],\n",
    "                'feature_counts': feature_counts  # Add feature counts to the structure\n",
    "            })\n",
    "\n",
    "    return desired_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb47a3-42c0-4e81-8d34-0ac34962da51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
