{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "95e51351-73ca-4bd3-95e1-4e5df4d557f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#MessageEvent.csv\n",
    "def extract_message(df, windows, timestamp):\n",
    "    #messages sent / received / total texts\n",
    "    windowed_messageevent = {}\n",
    "    before_esm = df[df.index <= timestamp]\n",
    "    for window_name, window_size in windows.items():\n",
    "        window_timedelta = pd.Timedelta(seconds=window_size)\n",
    "        windowed_data = before_esm[before_esm.index >= (timestamp - window_timedelta)]\n",
    "        unique_numbers_outgoing = []\n",
    "        unique_numbers_incoming = []\n",
    "        messages_outgoing = 0\n",
    "        messages_incoming = 0 \n",
    "        unique_messegers_outgoing = 0\n",
    "        unique_messegers_incoming = 0 \n",
    "        total_messages = 0 \n",
    "        for message_time, message_type, number, in windowed_data[['messageBox', 'number']].itertuples(index=True):\n",
    "            total_messages += 1\n",
    "            if message_type == 'SENT':\n",
    "                messages_outgoing += 1\n",
    "                if number not in unique_numbers_outgoing:\n",
    "                    unique_messegers_outgoing += 1\n",
    "                    unique_numbers_outgoing.append(number)\n",
    "            elif message_type == 'INBOX':\n",
    "                messages_incoming += 1\n",
    "                if number not in unique_numbers_incoming:\n",
    "                    unique_messegers_incoming += 1\n",
    "                    unique_numbers_incoming.append(number)\n",
    "        windowed_messageevent[f'{window_name}_unique_messegers_outgoing'] = unique_messegers_outgoing\n",
    "        windowed_messageevent[f'{window_name}_unique_messegers_incoming'] = unique_messegers_incoming\n",
    "        windowed_messageevent[f'{window_name}_total_messages'] = total_messages\n",
    "        \n",
    "    return windowed_messageevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8ce6f001-424b-4714-a5d2-10329a4f3019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#DeviceEvent.csv\n",
    "def extract_deviceevent(df, windows, timestamp):\n",
    "    # Number of times a phone is unlocked / time spent on phone\n",
    "    windowed_deviceevent = {}\n",
    "    before_esm = df[df.index <= timestamp]\n",
    "    for window_name, window_size in windows.items():\n",
    "        window_timedelta = pd.Timedelta(seconds=window_size)\n",
    "        windowed_data = before_esm[before_esm.index >= (timestamp - window_timedelta)]\n",
    "        times_unlocked = 0\n",
    "        time_spent_on_phone = 0\n",
    "        unlock_time = None  # Variable to store the timestamp of the last unlock event\n",
    "        for event_time, event_type in windowed_data[['type']].itertuples(index=True):\n",
    "            if event_type == 'UNLOCK':\n",
    "                times_unlocked += 1\n",
    "                unlock_time = event_time  # Update the unlock time\n",
    "            \n",
    "            elif event_type == 'SCREEN_OFF' and unlock_time is not None:\n",
    "                # Calculate the time spent on phone by subtracting unlock time from screen off time\n",
    "                time_spent_on_phone += (event_time - unlock_time).total_seconds()\n",
    "                unlock_time = None  # Reset the unlock time\n",
    "        proportion_time_spent_on_phone = time_spent_on_phone / window_size\n",
    "        # Store the calculated values in the windowed_deviceevent dictionary\n",
    "        windowed_deviceevent[f'{window_name}_times_unlocked'] = times_unlocked\n",
    "        windowed_deviceevent[f'{window_name}_proportion_of_time_spent_on_phone'] = proportion_time_spent_on_phone\n",
    "    \n",
    "    return windowed_deviceevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5ce480f-7f42-491a-8f11-8ebdfc98df7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#AppUsageEvent\n",
    "def entropy(labels):\n",
    "    n_labels = len(labels)\n",
    "    \n",
    "    if n_labels <= 1:\n",
    "        return 0\n",
    "    \n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    probs = counts / n_labels\n",
    "    entropy = -np.sum(probs * np.log2(probs))\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def extract_appusage(df, windows, timestamp):\n",
    "    windowed_appevent = {}\n",
    "    before_esm = df[df.index <= timestamp]\n",
    "    \n",
    "    for window_name, window_size in windows.items():\n",
    "        window_timedelta = pd.Timedelta(seconds=window_size)\n",
    "        window_start = timestamp - window_timedelta\n",
    "        windowed_data = before_esm[(before_esm.index >= window_start) & (before_esm.index <= timestamp)]\n",
    "        \n",
    "        # Count the number of events associated with each app category\n",
    "        app_category_counts = windowed_data['category'].value_counts().head(5)\n",
    "        \n",
    "        # Calculate the total number of app interactions in the window\n",
    "        total_interactions = len(windowed_data)\n",
    "        \n",
    "        # Calculate the proportion of time spent using each app category\n",
    "        app_category_proportions = app_category_counts / total_interactions\n",
    "        \n",
    "        # Calculate the entropy of the app category distribution\n",
    "        app_category_entropy = entropy(windowed_data['category'])\n",
    "        \n",
    "        # Create keys for each category in the windowed_appevent dictionary\n",
    "        for category, count in app_category_counts.items():\n",
    "            windowed_appevent[f'{window_name}_{category}_number_of_events'] = count\n",
    "            #windowed_appevent[f'{window_name}_{category}_proportion_of_time'] = app_category_proportions[category]\n",
    "        \n",
    "        # Add entropy to the windowed_appevent dictionary\n",
    "        windowed_appevent[f'{window_name}_category_entropy'] = app_category_entropy\n",
    "        \n",
    "    return windowed_appevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b35219a5-fc1f-4bb6-96ad-b567a8294f93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CallEvent.csv\n",
    "def extract_call(df, windows, timestamp):\n",
    "    #messages sent / received / total texts\n",
    "    windowed_callevent = {}\n",
    "    before_esm = df[df.index <= timestamp]\n",
    "    for window_name, window_size in windows.items():\n",
    "        window_timedelta = pd.Timedelta(seconds=window_size)\n",
    "        windowed_data = before_esm[before_esm.index >= (timestamp - window_timedelta)]\n",
    "        unique_numbers_outgoing = []\n",
    "        unique_numbers_incoming = []\n",
    "        unique_callers_outgoing = 0\n",
    "        unique_callers_incoming = 0 \n",
    "        time_spent_calling = 0\n",
    "        for call_time, number, call_type, duration in windowed_data[['number', 'type', 'duration']].itertuples(index=True): \n",
    "            time_spent_calling += duration\n",
    "            if call_type == 'OUTGOING':\n",
    "                if number not in unique_numbers_outgoing:\n",
    "                    unique_callers_outgoing += 1\n",
    "                    unique_numbers_outgoing.append(number)\n",
    "            elif call_type == 'INCOMING':\n",
    "                if number not in unique_numbers_incoming:\n",
    "                    unique_callers_incoming += 1\n",
    "                    unique_numbers_incoming.append(number)\n",
    "        windowed_callevent[f'{window_name}_unique_callers_outgoing'] = unique_callers_outgoing\n",
    "        windowed_callevent[f'{window_name}_unique_callers_incoming'] = unique_callers_incoming\n",
    "        windowed_callevent[f'{window_name}_time_spent_calling'] = time_spent_calling\n",
    "    return windowed_callevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "466c27be-9692-4f01-a337-2b701100144c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Location.csv\n",
    "# def calculate_entropy(cluster_counts):\n",
    "#     total_time = cluster_counts.sum()\n",
    "#     cluster_proportions = cluster_counts / total_time\n",
    "#     entropy = -np.sum([p * np.log2(p) for p in cluster_proportions.values if p != 0])\n",
    "#     return entropy\n",
    "\n",
    "\n",
    "# def extract_location(df, windows, timestamp):\n",
    "#     windowed_location = {}\n",
    "#     before_esm = df[df.index <= timestamp]\n",
    "#     # Iterate through each window\n",
    "#     for window_name, window_size in windows.items():\n",
    "#         window_timedelta = pd.Timedelta(seconds=window_size)\n",
    "#         windowed_data = before_esm[before_esm.index >= (timestamp - window_timedelta)]\n",
    "#         # Calculate cluster counts within the window\n",
    "#         cluster_counts = windowed_data['cluster'].value_counts()\n",
    "        \n",
    "#         # Calculate entropy for the window\n",
    "#         window_entropy = calculate_entropy(cluster_counts)\n",
    "        \n",
    "#         # Store entropy in the windowed_location dictionary\n",
    "#         windowed_location[f'{window_name}_location_entropy'] = window_entropy\n",
    "    \n",
    "#     return windowed_location\n",
    "\n",
    "def calculate_entropy(cluster_counts):\n",
    "    total_time = cluster_counts.sum()\n",
    "    \n",
    "    if total_time == 0:\n",
    "        return 0  # Return zero entropy if there are no counts\n",
    "\n",
    "    cluster_proportions = cluster_counts / total_time\n",
    "    \n",
    "    # Filter out zero proportions\n",
    "    cluster_proportions = cluster_proportions[cluster_proportions > 0]\n",
    "    \n",
    "    # Calculate entropy\n",
    "    entropy = -np.sum(cluster_proportions * np.log2(cluster_proportions))\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "# Define the extract_location function\n",
    "def extract_location(df, windows, timestamp):\n",
    "    windowed_location = {}\n",
    "    before_esm = df[df.index <= timestamp]\n",
    "    \n",
    "    # Iterate through each window\n",
    "    for window_name, window_size in windows.items():\n",
    "        window_timedelta = pd.Timedelta(seconds=window_size)\n",
    "        windowed_data = before_esm[before_esm.index >= (timestamp - window_timedelta)]\n",
    "        \n",
    "        # Calculate cluster counts within the window\n",
    "        cluster_counts = windowed_data['cluster'].value_counts()\n",
    "        \n",
    "        # Calculate entropy for the window\n",
    "        window_entropy = calculate_entropy(cluster_counts)\n",
    "        \n",
    "        # Store entropy in the windowed_location dictionary\n",
    "        windowed_location[f'{window_name}_location_entropy'] = window_entropy\n",
    "    \n",
    "    return windowed_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1d30cd-58c4-4f53-99dc-07b786041002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generic_entropy(data):\n",
    "    value_counts = data.value_counts()\n",
    "    probabilities = value_counts / len(data)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n",
    "\n",
    "def extract_generic_window_features(df, windows, timestamp):\n",
    "    windowed_features = {}\n",
    "    before_esm = df[df.index <= timestamp]\n",
    "        \n",
    "    for window_name, window_size in windows.items():\n",
    "        window_timedelta = pd.Timedelta(seconds=window_size)\n",
    "        windowed_data = before_esm[before_esm.index >= (timestamp - window_timedelta)]\n",
    "\n",
    "        # Calculate mean, median, and standard deviation for numeric columns\n",
    "        numeric_cols = windowed_data.select_dtypes(include=np.number).columns\n",
    "        for col in numeric_cols:\n",
    "            col_mean = windowed_data[col].mean()\n",
    "            col_median = windowed_data[col].median()\n",
    "            col_std = windowed_data[col].std()\n",
    "            col_entropy = calculate_entropy(windowed_data[col])\n",
    "            windowed_features[f'{window_name}_{col}_mean'] = col_mean\n",
    "            windowed_features[f'{window_name}_{col}_median'] = col_median\n",
    "            windowed_features[f'{window_name}_{col}_std'] = col_std\n",
    "            windowed_features[f'{window_name}_{col}_entropy'] = col_entropy\n",
    "    \n",
    "    return windowed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71dd5599-c42f-44d5-b7bb-66cc903283c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_windowed_data(all_participants_data, esm_responses, user_info, processing_functions, generic_windows):\n",
    "    windowed_data_list = []  # List to store dictionaries of windowed features\n",
    "    \n",
    "    esm_responses = pd.merge(user_info, esm_responses, on='Pcode')\n",
    "    esm_responses.sort_values(by=['Pcode', 'ResponseTime'], inplace=True)\n",
    "    esm_responses.set_index('ResponseTime', inplace = True)\n",
    "    \n",
    "    # Iterate through each participant's data dictionary\n",
    "    for participant_id, participant_data in all_participants_data.items():\n",
    "        # Get all ESM responses for the current participant\n",
    "        participant_esm_responses = esm_responses[esm_responses['Pcode'] == participant_id]\n",
    "        \n",
    "        # Iterate through each ESM response for the participant\n",
    "        for index, esm_response in participant_esm_responses.iterrows():\n",
    "            timestamp = index\n",
    "            timestamp = pd.Timestamp(timestamp)\n",
    "            p_code = esm_response['Pcode']\n",
    "            stress = esm_response['Stress_binary']\n",
    "            valence = esm_response['Valence_binary']\n",
    "            arousal = esm_response['Arousal_binary']\n",
    "            user_info_row = user_info[user_info['Pcode'] == participant_id].iloc[0]\n",
    "            age = user_info_row['Age']\n",
    "            gender = user_info_row['Gender']\n",
    "            openness = user_info_row['Openness']\n",
    "            conscientiousness = user_info_row['Conscientiousness']\n",
    "            neuroticism = user_info_row['Neuroticism']\n",
    "            extraversion = user_info_row['Extraversion']\n",
    "            agreeableness = user_info_row['Agreeableness']\n",
    "            pss10 = user_info_row['PSS10']\n",
    "            phq9 = user_info_row['PHQ9']\n",
    "            ghq12 = user_info_row['GHQ12']     \n",
    "        \n",
    "            \n",
    "            windowed_features = {\n",
    "                'ResponseTime': timestamp,\n",
    "                'Pcode': p_code,\n",
    "                'Stress_binary': stress,\n",
    "                'Valence_binary': valence,\n",
    "                'Arousal_binary': arousal,\n",
    "                'Age': age,\n",
    "                'Gender': gender,\n",
    "                'Openness': openness,\n",
    "                'Conscientiousness': conscientiousness,\n",
    "                'Neuroticism': neuroticism,\n",
    "                'Extraversion': extraversion,\n",
    "                'Agreeableness': agreeableness,\n",
    "                'PSS_last_week': pss10,\n",
    "                'PHQ_last_week': phq9,\n",
    "                'GHQ_last_week': ghq12\n",
    "                \n",
    "            }\n",
    "            \n",
    "            for dataframe_name, dataframe in participant_data.items():\n",
    "                if dataframe_name == 'sleep_proxies':\n",
    "                    continue\n",
    "                if dataframe_name in processing_functions.keys():\n",
    "                    proc_function, proc_windows = processing_functions[dataframe_name]\n",
    "                    additional_features = proc_function(dataframe, proc_windows, timestamp)\n",
    "                    windowed_features.update(additional_features)\n",
    "\n",
    "                else:\n",
    "                    windows = generic_windows\n",
    "                    generic_features = extract_generic_window_features(dataframe, windows, timestamp)\n",
    "                    windowed_features.update(generic_features)\n",
    "                \n",
    "            windowed_data_list.append(windowed_features)\n",
    "    \n",
    " \n",
    "    windowed_data_df = pd.DataFrame(windowed_data_list)\n",
    "    windowed_data_df.set_index(['ResponseTime', 'Pcode'], inplace = True)\n",
    "    return windowed_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c053590-b0c1-4b12-9a48-9adbdc9d56db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_sleep_proxy(all_participants_data, windowed_df):\n",
    "    windowed_df['previous_nights_sleep_proxy'] = np.NaN\n",
    "    for (timestamp, Pcode), row in windowed_df.iterrows():\n",
    "        sleep_proxies = all_participants_data[Pcode]['sleep_proxies']\n",
    "        for date, sleep_proxy in sleep_proxies.iterrows():\n",
    "            if timestamp.date() == date:\n",
    "                windowed_df.loc[(timestamp, Pcode), 'previous_nights_sleep_proxy'] = sleep_proxy['SleepProxy']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
